import streamlit as st
from transformers import pipeline

# 1) ุชุญููู ูููุฐุฌ ุฌุงูุฒ ูู Hugging Face (ูููู ุชุบููุฑู ูุงุญูุงู ููููุฐุฌ ุฃููู ุฃู ุฎุงุต)
qa_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")

# 2) ูุงุฌูุฉ ุงููุณุชุฎุฏู
st.set_page_config(page_title="ุงููุนูู ุงูุฐูู", page_icon="๐", layout="centered")

st.title("๐ ุงููุนูู ุงูุฐูู ุจุงูุฐูุงุก ุงูุตูุงุนู")
st.write("ุงุณุฃู ุฃู ุณุคุงู ูู ุงูุฑูุงุถูุงุชุ ุงูููุฒูุงุก ุฃู ุฃู ูุงุฏุฉุ ูุณุฃุฌูุจู ููุนูู ุฎุตูุตู.")

# ุฅุฏุฎุงู ุณุคุงู ุงูุทุงูุจ
question = st.text_area("โ๏ธ ุงูุชุจ ุณุคุงูู ููุง:")

if st.button("ุฅุฌุงุจุฉ"):
    if question.strip():
        with st.spinner("โณ ุฌุงุฑู ุงูุชูููุฑ..."):
            # 3) ุชูููุฏ ุงูุฅุฌุงุจุฉ
            response = qa_pipeline(question, max_length=200, num_return_sequences=1)
            answer = response[0]['generated_text']

            # 4) ุนุฑุถ ุงูุฅุฌุงุจุฉ
            st.subheader("โ ุงูุฅุฌุงุจุฉ:")
            st.write(answer)

            # 5) ุงูุชุฑุงุญ ุชูุฑูู ุฅุถุงูู
            st.subheader("๐ ุชูุฑูู ุฅุถุงูู ูู:")
            st.write(f"ุฌุฑูุจ ุญู ุณุคุงู ูุดุงุจู: {question} ููู ุจุฃุฑูุงู ุฃู ูุนุทูุงุช ูุฎุชููุฉ.")
    else:
        st.warning("ูู ูุถูู ุงูุชุจ ุณุคุงูุงู ุฃููุงู.")
